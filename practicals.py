# -*- coding: utf-8 -*-
"""Practicals

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CAYuKJsi72xkdbdarydsBlUi8SSIeDTQ

**Ques1.**
"""

import pandas as pd
DL={'Boys':[72,68,70,69,74], 'Girls':[63,65,69,62,61]}
df=pd.DataFrame(DL).to_dict(orient="records")
df

"""**Ques2.) Using Numpy**"""

import numpy as np
x=np.array([[10,30],[20,60],[40,100]])
print("Mean of each row: ",x.mean(axis=1))
print("Standard Deviation:", np.std(x,axis=1))
print("Variance:",np.var(x,axis=1))

B = np.array([56, 48, 22, 41, 78, 91, 24, 46, 8, 33])
print("The original array is: ")
print(B)
i=np.argsort(B)
print("Indices of the sorted elements of the given array: ")
print(i)

R=int(input("Enter the number of row: "))
C=int(input("Enter the number of columns: "))
matrix=[]
print("Enter the entries row-wise: ")
for i in range(R):
    a=[]
    for j in range(C):
        a.append(int(input()))
    matrix.append(a)
for i in range(R):
    for j in range(C):
        print(matrix[i][j],end=" ")
    print()
print(np.shape(matrix))
print(type(matrix))
newarray=np.transpose(matrix)
print(newarray)

import math
arr=[1,4,3,0,4,7,0,0,np.nan,1]
arr1=[]
arr2=[]
arr3=[]
for i,ele in enumerate(arr):
    if(ele!=0 and not math.isnan(ele)):
        arr1.append(i)
    elif(ele==0):
        arr2.append(i)
    elif(math.isnan(ele)):
        arr3.append(i)
print(arr1)
print(arr2)
print(arr3)

"""**Ques3.) Create a dataframe having at least 3 columns and 50 rows
to store numeric data generated using a random function. Replace 10% of
the values by null values whose index positions are generated using
random function.**
"""

import pandas as pd
import numpy as np
df=pd.DataFrame(np.random.randint(0,100,size=(50,3)),columns=['a','b','c'])
num_null=int(df.size*0.1)
num_index=np.random.choice(df.index,num_null,replace=False)
df.loc[num_index]=np.nan;
df.head()

df.isnull()
df.isnull().sum()

df1=df.dropna(axis=0,thresh=5)
print(df1)

maxrow=df.sum(axis=1).idxmax()
print(maxrow)
df=df.drop(maxrow)
df

df2=df.sort_values(by='a')
df2

df.drop_duplicates(subset='a', keep='first', inplace=True)
                    #column     #keep 1st x or 2nd   #replace this data with df or not
df

c1=df['a']
c2=df['b']
c3=df['c']
corel=c1.corr(c2)
print(corel)
covar=c2.cov(c3)
print(covar)

z_scores=(df-df.mean())/df.std()
outliers=(z_scores>3).any(axis=1)
df=df[~outliers]
df

df['b_bins']=pd.cut(df['b'],5)
df

"""**Ques4.) Consider two excel files having attendance of a workshop’s
participants for two days. Each file has three fields ‘Name’, ‘Time of
joining’, duration (in minutes) where names are unique within a file. Note
that duration may take one of three values (30, 40, 50) only. Import the
data into two DataFrames and do the following**
"""

import pandas as pd
file1=pd.ExcelFile('Attendance1.xlsx')
file2=pd.ExcelFile('Attendance2.xlsx')
f1=pd.read_excel(file1, file1.sheet_names[0])
f2=pd.read_excel(file2, file2.sheet_names[0])
print(f1)
print(f2)

merging=pd.merge(f1,f2,on=['Name'])
print(merging['Name'])

merging2=pd.merge(f1,f2,on=['Name'],how="outer")
merging2['Name']

concatination=pd.concat([f1,f2],keys=['file1','file2'])
print(concatination)

new_file=pd.merge(f1,f2)
df2=new_file.set_index(keys=[new_file.columns[0],new_file.columns[2]])
df2.describe()

"""**Ques5.) Taking iris data from https://archive.ics.uci.edu/dataset/53/iris or import**"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
#from sklearn.datasets import load_iris
data=load_iris()
df=pd.DataFrame(data.data,columns=data.feature_names)
df['target']=data.target
df['class']=data.target_names[df['target']]
df

class_counts=df['class'].value_counts()
plt.figure(figsize=(6,4))
plt.bar(class_counts.index,class_counts.values)
plt.xlabel('Class')
plt.ylabel('Frequency')
plt.title('Class label frequency')
plt.show()

plt.figure(figsize=(6,4))
sns.scatterplot(x='sepal width (cm)',y='petal width (cm)',hue='class',data=df)
plt.xlabel('Sepal Width (cm)')
plt.ylabel('Petal Width (cm)')
plt.legend(title='Class')
plt.show()

plt.figure(figsize=(6,4))
sns.kdeplot(df['petal length (cm)'], fill=True, color='Black')
plt.title('Density Disribution of Petal length in Iris Dataset')
plt.xlabel('Petal Length (cm)')
plt.ylabel('Density')
plt.show()

sns.set(style="ticks")
sns.pairplot(df,hue="class",diag_kind="kde")
plt.show()

"""**Ques6.) Weather Forcasting dataset**"""

data2=pd.read_csv('https://raw.githubusercontent.com/codebasics/py/master/pandas/14_ts_datetimeindex/aapl.csv')
print(file.head())

data3=data2.groupby('Open')['Volume'].mean()
data3

data2['Date']=pd.to_datetime(data2['Date'])
data2=data2.set_index('Date')
data2=data2.reindex(pd.date_range('2017-01-01','2017-12-31',freq='D'))
data2.groupby(data2.index.time).ffill()

data2['Date']=pd.to_datetime(data2['Date'])
data2.head(10)

df_agg=data2.groupby(['High','Low']).agg({'Volume':sum})
result=df_agg['Volume'].groupby(level=0, group_keys=False)
print(result.nlargest())

groups=data2.groupby(['Close', pd.cut(data2.Open, 3)])
result=groups.size().unstack()
print(result)

"""**Ques7.) Consider a data frame**"""

import pandas as pd
df3 = pd.DataFrame({'Name':['Mudit Chauhan','Seema Chopra','Rani Gupta','Aditya Narayan',
                            'Sanjeev Sahani','Prakash Kumar','Ritu Agarwal','Akshay Goel',
                            'Meeta Kulkarni','Preeti Ahuja','Sunil Das Gupta','Sonali Sapre',
                            'Rashmi Talwar','Ashish Dubey','Kiran Sharma','Sameer Bansal'],
                    'Birth_Month': ['December','January','March','October','February',
                                    'December','September','August','July','November',
                                    'April','January','May','June','February','October'],
                    'Gender': ['M','F','F','M','M','M','F','M','F','F','M','F','F','M','F','M'],
                    'Pass_division':[3,2,1,1,2,3,1,1,2,2,3,1,3,2,2,1]})

df3

pd.get_dummies(df3.Gender)

pd.get_dummies(df3.Gender, drop_first=True)

gender_dummies=pd.get_dummies(df3.Gender, prefix='Gender')
gender_dummies

df3=pd.concat([df3, gender_dummies], axis=1)
df3.head()

pass_dummies=pd.get_dummies(df3.Pass_division, prefix='pass')
pass_dummies.head()

df3=pd.concat([df3,pass_dummies], axis=1)
df3.head()

df3

sort_order=['January','February','March','April','May','June','July','August',
	    'September','October','November','December']
df3.index=pd.CategoricalIndex(df3['Birth_Month'],categories=sort_order, ordered=True)
df3=df3.sort_index().reset_index(drop=True)
df3

"""**Ques8.) Consider the dataset of families**"""

import pandas as pd
df4 = pd.DataFrame({ 'Name': ['Shah','Vats','Vats','Kumar',
                              'Vats','Kumar','Shah','Shah','Kumar','Vats'],
                    'Gender': ['Male','Male' ,'Female','Female','Female',
                               'Male','Male','Female','Fem ale','Male'],
                    'Monthly_Income (Rs)': [114000,65000,43150,69500,155000,
                                            103000,55000,112400,81030,71900]})
df4

sumOfIncome = df4.groupby(by=['Name'], as_index=False)['Monthly_Income (Rs)'].sum()
sumOfIncome

grouped = df4.groupby(['Name'], sort=False)['Monthly_Income (Rs)'].max()
grouped

res = df4[df4['Monthly_Income (Rs)'] > 60000]
res

res4 = df4[(df4['Name'] == 'Shah') & (df4['Gender'] == 'Female')]
res4.mean()

